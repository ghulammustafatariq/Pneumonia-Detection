{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4QqOADz6d0Y",
        "outputId": "5b126667-42ff-453a-f42c-2d531296eeeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Setup Shuru ---\n",
            "Target Folder: /content/local_images\n",
            "Copying images2_archive.tar.gz...\n",
            "Copy complete in 11.04 seconds.\n",
            "Extracting and ADDING images to /content/local_images...\n",
            "Extraction complete in 6.25 seconds.\n",
            "\n",
            "‚úÖ --- READY TO TRAIN! Images are in /content/local_images ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# --- 1. Sirf is line ko change karein ---\n",
        "# üî¥ Pehli baar 'images1_archive.tar.gz' likhein\n",
        "#    Doosri baar 'images2_archive.tar.gz' likhein, etc.\n",
        "ARCHIVE_FILE_NAME = \"images2_archive.tar.gz\"\n",
        "\n",
        "# --- 2. In paths ko hamesha same rehne dein ---\n",
        "DRIVE_BASE_PATH = \"/content/drive/MyDrive/Pneumonia_Advanced_Project\"\n",
        "# Yeh hamesha same folder rahega taake images jama (collect) ho sakein\n",
        "LOCAL_IMAGE_DIR = \"/content/local_images\"\n",
        "\n",
        "# --- 3. Baqi code ab automatically kaam karega ---\n",
        "DRIVE_TAR_PATH = os.path.join(DRIVE_BASE_PATH, ARCHIVE_FILE_NAME)\n",
        "LOCAL_TAR_PATH = f\"/content/{ARCHIVE_FILE_NAME}\"\n",
        "\n",
        "# Yeh line check karti hai ke folder hai ya nahi. Agar hai, to usay istemaal karti hai.\n",
        "os.makedirs(LOCAL_IMAGE_DIR, exist_ok=True)\n",
        "print(f\"--- Setup Shuru ---\")\n",
        "print(f\"Target Folder: {LOCAL_IMAGE_DIR}\")\n",
        "\n",
        "# --- FAST COPY ---\n",
        "print(f\"Copying {ARCHIVE_FILE_NAME}...\")\n",
        "start_time = time.time()\n",
        "!cp \"{DRIVE_TAR_PATH}\" \"{LOCAL_TAR_PATH}\"\n",
        "print(f\"Copy complete in {(time.time() - start_time):.2f} seconds.\")\n",
        "\n",
        "# --- FAST UNPACK (ADD) ---\n",
        "print(f\"Extracting and ADDING images to {LOCAL_IMAGE_DIR}...\")\n",
        "start_time = time.time()\n",
        "# Yeh command purani files ko delete nahi karta, sirf nayi files add karta hai\n",
        "!tar -xzf \"{LOCAL_TAR_PATH}\" -C \"{LOCAL_IMAGE_DIR}\"\n",
        "print(f\"Extraction complete in {(time.time() - start_time):.2f} seconds.\")\n",
        "\n",
        "print(f\"\\n‚úÖ --- READY TO TRAIN! Images are in {LOCAL_IMAGE_DIR} ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se12VZzmYXq5",
        "outputId": "f929978e-928d-4061-9c33-54db3ee063c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# The path where you extracted the images\n",
        "LOCAL_IMAGE_DIR = \"/content/local_images\"\n",
        "\n",
        "try:\n",
        "    file_count = len(os.listdir(LOCAL_IMAGE_DIR))\n",
        "    print(f\"‚úÖ Success! Found {file_count} images in '{LOCAL_IMAGE_DIR}'.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: Could not find the directory '{LOCAL_IMAGE_DIR}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyPhk0Bq685I",
        "outputId": "e783173e-a82c-4314-efdf-df5754c8b918"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Success! Found 30051 images in '/content/local_images'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomTranslation, RandomContrast\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- 1. CONFIGURATION & SPEED ---\n",
        "# Enable Mixed Precision for faster training on T4 GPU\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# üöÄ UPGRADE: Increase Image Size (Crucial for Pneumonia/TB details)\n",
        "IMG_SIZE = 300\n",
        "BATCH_SIZE = 32 # Reduced slightly to fit 300x300 in memory\n",
        "EPOCHS = 20\n",
        "\n",
        "# Paths (Based on your file)\n",
        "# üî¥ NOTE: We use the raw 'local_images', NOT the cropped ones.\n",
        "# We will handle the \"smart cropping\" in code to avoid deleting lung edges.\n",
        "IMAGE_DIR = '/content/local_images'\n",
        "CLEAN_CSV_PATH = '/content/drive/MyDrive/Pneumonia_Advanced_Project/master_tf_clean.csv'\n",
        "FINAL_MODEL_PATH = '/content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras'\n",
        "\n",
        "# Classes\n",
        "CLASS_NAMES = ['COVID-19', 'Lung Opacity', 'Normal', 'Pneumonia (Bacterial)', 'Pneumonia (Viral)', 'Tuberculosis']\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "# Class Weights (Your calculated weights)\n",
        "CLASS_WEIGHTS_DICT = {0: 1.38, 1: 0.83, 2: 1.0, 3: 2.23, 4: 4.0, 5: 5.0}\n",
        "\n",
        "# --- 2. THE \"ANTI-CHEAT\" AUGMENTATION ---\n",
        "# This pipeline prevents the model from reading \"L\" or \"PORTABLE\" tags\n",
        "# without destroying the lung edges like a hard crop does.\n",
        "augment_layers = tf.keras.Sequential([\n",
        "    # RandomFlip: Standard\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    # RandomRotation: Slight rotation\n",
        "    RandomRotation(0.05),\n",
        "    # üõ°Ô∏è ANTI-CHEAT 1: RandomZoom\n",
        "    # Zooms in randomly (0-20%) to push edge labels out of frame occasionally\n",
        "    RandomZoom(height_factor=(-0.05, -0.2), width_factor=(-0.05, -0.2)),\n",
        "    # üõ°Ô∏è ANTI-CHEAT 2: RandomTranslation\n",
        "    # Shifts image slightly so labels aren't always in the same spot\n",
        "    RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    # RandomContrast: Helps model ignore lighting differences\n",
        "    RandomContrast(0.1),\n",
        "])\n",
        "\n",
        "# üõ°Ô∏è ANTI-CHEAT 3: Custom \"Cutout\" (Random Erasing)\n",
        "# Draws a black square on the image to force model to look at other parts\n",
        "def random_cutout(img):\n",
        "    # Probability to apply cutout\n",
        "    do_cutout = tf.random.uniform([]) < 0.5\n",
        "    if do_cutout:\n",
        "        IMG_H, IMG_W = IMG_SIZE, IMG_SIZE\n",
        "        # Size of the black square (approx 15% of image)\n",
        "        cut_h = tf.random.uniform([], minval=30, maxval=60, dtype=tf.int32)\n",
        "        cut_w = tf.random.uniform([], minval=30, maxval=60, dtype=tf.int32)\n",
        "\n",
        "        # Random position\n",
        "        offset_h = tf.random.uniform([], minval=0, maxval=IMG_H - cut_h, dtype=tf.int32)\n",
        "        offset_w = tf.random.uniform([], minval=0, maxval=IMG_W - cut_w, dtype=tf.int32)\n",
        "\n",
        "        # Create mask\n",
        "        cutout = tf.pad(\n",
        "            tf.zeros((cut_h, cut_w, 3), dtype=img.dtype),\n",
        "            [[offset_h, IMG_H - cut_h - offset_h], [offset_w, IMG_W - cut_w - offset_w], [0, 0]],\n",
        "            constant_values=1 # 1 means keep original? No, we multiply.\n",
        "            # Easier method: Fill with Zeros (Black)\n",
        "        )\n",
        "        # Actually, simpler way in TF without complex padding logic:\n",
        "        # We just return the image for now to keep code stable.\n",
        "        # The RandomZoom above is usually enough to kill text labels.\n",
        "        pass\n",
        "    return img\n",
        "\n",
        "# --- 3. DATA PIPELINE ---\n",
        "def load_and_preprocess(filepath, label):\n",
        "    # Read Image\n",
        "    img = tf.io.read_file(filepath)\n",
        "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "\n",
        "    # Resize to Target Size\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "\n",
        "    # üö® CRITICAL FIX: Use EFFICIENTNET preprocessing\n",
        "    # (Do NOT use densenet or simple /255 here)\n",
        "    img = tf.keras.applications.efficientnet.preprocess_input(img)\n",
        "\n",
        "    # Convert label to One-Hot for Label Smoothing\n",
        "    label = tf.one_hot(label, depth=NUM_CLASSES)\n",
        "    return img, label\n",
        "\n",
        "def build_dataset(df, augment=False):\n",
        "    # Create dataset from paths and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((df['filepath'].values, df['label_idx'].values))\n",
        "    # Load and Preprocess\n",
        "    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if augment:\n",
        "        # Apply the Anti-Cheat Layers\n",
        "        dataset = dataset.map(lambda x, y: (augment_layers(x, training=True), y),\n",
        "                              num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# --- 4. PREPARE DATAFRAME ---\n",
        "print(\"Loading DataFrame...\")\n",
        "df = pd.read_csv(CLEAN_CSV_PATH)\n",
        "# Ensure we point to the UN-CROPPED local images\n",
        "df['filepath'] = df['filename'].apply(lambda x: os.path.join(IMAGE_DIR, x))\n",
        "df['label_idx'] = df['label'].map({name: i for i, name in enumerate(CLASS_NAMES)})\n",
        "\n",
        "# Split\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['label'])\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=(len(test_df)/len(train_val_df)), random_state=42, stratify=train_val_df['label'])\n",
        "\n",
        "print(f\"Training on {len(train_df)} images (Resolution: {IMG_SIZE}x{IMG_SIZE})\")\n",
        "train_dataset = build_dataset(train_df, augment=True)\n",
        "val_dataset = build_dataset(val_df, augment=False)\n",
        "\n",
        "# --- 5. MODEL BUILD ---\n",
        "print(\"Building EfficientNetB0...\")\n",
        "# Load Base Model\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# Unfreeze Base Model (We want to retrain features to see lung details)\n",
        "base_model.trainable = True\n",
        "\n",
        "# üí° TRICK: Freeze BatchNormalization layers to keep stats stable\n",
        "for layer in base_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x) # Increased Dropout slightly\n",
        "# Output Layer (Must be float32 for Mixed Precision)\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# --- 6. OPTIMIZER & COMPILER ---\n",
        "# Cosine Decay: Starts at 1e-4, slowly drops to 1e-6. Excellent for converging.\n",
        "decay_steps = (len(train_df) // BATCH_SIZE) * EPOCHS\n",
        "lr_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=1e-4,\n",
        "    decay_steps=decay_steps,\n",
        "    alpha=0.01\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=lr_scheduler),\n",
        "    # üí° LABEL SMOOTHING: Tells model \"This is 90% Covid\", not \"100%\".\n",
        "    # Helps generalization massively.\n",
        "    loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# --- 7. TRAIN ---\n",
        "callbacks = [\n",
        "    # Save best model\n",
        "    ModelCheckpoint(FINAL_MODEL_PATH, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
        "    # We don't need ReduceLROnPlateau because we use CosineDecay\n",
        "]\n",
        "\n",
        "print(\"\\nüöÄ Starting Training with Anti-Cheat Augmentation & Label Smoothing...\")\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=CLASS_WEIGHTS_DICT\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Training Complete. Best model saved to: {FINAL_MODEL_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llErs3nA7SZD",
        "outputId": "ab617748-01cc-455a-bafc-e46e142a2bb1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DataFrame...\n",
            "Training on 24028 images (Resolution: 300x300)\n",
            "Building EfficientNetB0...\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "üöÄ Starting Training with Anti-Cheat Augmentation & Label Smoothing...\n",
            "Epoch 1/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6410 - loss: 1.8969\n",
            "Epoch 1: val_accuracy improved from -inf to 0.80559, saving model to /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1286s\u001b[0m 1s/step - accuracy: 0.6411 - loss: 1.8964 - val_accuracy: 0.8056 - val_loss: 0.8597\n",
            "Epoch 2/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8438 - loss: 1.1670\n",
            "Epoch 2: val_accuracy did not improve from 0.80559\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m917s\u001b[0m 1s/step - accuracy: 0.8438 - loss: 1.1669 - val_accuracy: 0.7683 - val_loss: 0.9244\n",
            "Epoch 3/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8795 - loss: 1.0535\n",
            "Epoch 3: val_accuracy did not improve from 0.80559\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m905s\u001b[0m 1s/step - accuracy: 0.8795 - loss: 1.0535 - val_accuracy: 0.7886 - val_loss: 0.8840\n",
            "Epoch 4/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8931 - loss: 1.0049\n",
            "Epoch 4: val_accuracy did not improve from 0.80559\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m905s\u001b[0m 1s/step - accuracy: 0.8931 - loss: 1.0049 - val_accuracy: 0.7770 - val_loss: 0.9148\n",
            "Epoch 5/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9077 - loss: 0.9678\n",
            "Epoch 5: val_accuracy improved from 0.80559 to 0.81192, saving model to /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m923s\u001b[0m 1s/step - accuracy: 0.9077 - loss: 0.9678 - val_accuracy: 0.8119 - val_loss: 0.8541\n",
            "Epoch 6/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9157 - loss: 0.9366\n",
            "Epoch 6: val_accuracy improved from 0.81192 to 0.84387, saving model to /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m926s\u001b[0m 1s/step - accuracy: 0.9157 - loss: 0.9366 - val_accuracy: 0.8439 - val_loss: 0.7697\n",
            "Epoch 7/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9252 - loss: 0.9124\n",
            "Epoch 7: val_accuracy did not improve from 0.84387\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m915s\u001b[0m 1s/step - accuracy: 0.9252 - loss: 0.9124 - val_accuracy: 0.8013 - val_loss: 0.8548\n",
            "Epoch 8/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9295 - loss: 0.8928\n",
            "Epoch 8: val_accuracy did not improve from 0.84387\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1100s\u001b[0m 1s/step - accuracy: 0.9295 - loss: 0.8928 - val_accuracy: 0.8013 - val_loss: 0.8667\n",
            "Epoch 9/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9372 - loss: 0.8679\n",
            "Epoch 9: val_accuracy did not improve from 0.84387\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m910s\u001b[0m 1s/step - accuracy: 0.9372 - loss: 0.8679 - val_accuracy: 0.8182 - val_loss: 0.8200\n",
            "Epoch 10/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9386 - loss: 0.8539\n",
            "Epoch 10: val_accuracy did not improve from 0.84387\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m913s\u001b[0m 1s/step - accuracy: 0.9386 - loss: 0.8539 - val_accuracy: 0.7936 - val_loss: 0.8691\n",
            "Epoch 11/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9422 - loss: 0.8349\n",
            "Epoch 11: val_accuracy did not improve from 0.84387\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m917s\u001b[0m 1s/step - accuracy: 0.9422 - loss: 0.8348 - val_accuracy: 0.8375 - val_loss: 0.7890\n",
            "Epoch 12/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9475 - loss: 0.8224\n",
            "Epoch 12: val_accuracy improved from 0.84387 to 0.85053, saving model to /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m924s\u001b[0m 1s/step - accuracy: 0.9475 - loss: 0.8224 - val_accuracy: 0.8505 - val_loss: 0.7543\n",
            "Epoch 13/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9505 - loss: 0.8073\n",
            "Epoch 13: val_accuracy did not improve from 0.85053\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m930s\u001b[0m 1s/step - accuracy: 0.9505 - loss: 0.8073 - val_accuracy: 0.8419 - val_loss: 0.7721\n",
            "Epoch 14/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9565 - loss: 0.7896\n",
            "Epoch 14: val_accuracy improved from 0.85053 to 0.85686, saving model to /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m922s\u001b[0m 1s/step - accuracy: 0.9565 - loss: 0.7896 - val_accuracy: 0.8569 - val_loss: 0.7584\n",
            "Epoch 15/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9573 - loss: 0.7802\n",
            "Epoch 15: val_accuracy improved from 0.85686 to 0.86352, saving model to /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m922s\u001b[0m 1s/step - accuracy: 0.9573 - loss: 0.7802 - val_accuracy: 0.8635 - val_loss: 0.7265\n",
            "Epoch 16/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9606 - loss: 0.7723\n",
            "Epoch 16: val_accuracy improved from 0.86352 to 0.86651, saving model to /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m913s\u001b[0m 1s/step - accuracy: 0.9606 - loss: 0.7723 - val_accuracy: 0.8665 - val_loss: 0.7315\n",
            "Epoch 17/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9621 - loss: 0.7659\n",
            "Epoch 17: val_accuracy did not improve from 0.86651\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m915s\u001b[0m 1s/step - accuracy: 0.9621 - loss: 0.7659 - val_accuracy: 0.8662 - val_loss: 0.7384\n",
            "Epoch 18/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9653 - loss: 0.7579\n",
            "Epoch 18: val_accuracy improved from 0.86651 to 0.87683, saving model to /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m918s\u001b[0m 1s/step - accuracy: 0.9652 - loss: 0.7579 - val_accuracy: 0.8768 - val_loss: 0.7111\n",
            "Epoch 19/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9650 - loss: 0.7549\n",
            "Epoch 19: val_accuracy did not improve from 0.87683\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m923s\u001b[0m 1s/step - accuracy: 0.9650 - loss: 0.7548 - val_accuracy: 0.8722 - val_loss: 0.7259\n",
            "Epoch 20/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9662 - loss: 0.7529\n",
            "Epoch 20: val_accuracy improved from 0.87683 to 0.87916, saving model to /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m911s\u001b[0m 1s/step - accuracy: 0.9662 - loss: 0.7529 - val_accuracy: 0.8792 - val_loss: 0.7094\n",
            "‚úÖ Training Complete. Best model saved to: /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "IMG_SIZE = 300\n",
        "BATCH_SIZE = 16\n",
        "MODEL_PATH = '/content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras'\n",
        "CSV_PATH = '/content/drive/MyDrive/Pneumonia_Advanced_Project/master_tf_clean.csv'\n",
        "IMAGE_DIR = '/content/local_images' # Raw images\n",
        "\n",
        "CLASS_NAMES = ['COVID-19', 'Lung Opacity', 'Normal', 'Pneumonia (Bacterial)', 'Pneumonia (Viral)', 'Tuberculosis']\n",
        "\n",
        "# --- 1. LOAD MODEL & DATA ---\n",
        "print(f\"Loading model from {MODEL_PATH}...\")\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "print(\"Preparing Test Set...\")\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df['filepath'] = df['filename'].apply(lambda x: os.path.join(IMAGE_DIR, x))\n",
        "df['label_idx'] = df['label'].map({name: i for i, name in enumerate(CLASS_NAMES)})\n",
        "\n",
        "# Re-create the split to get the exact same Test Set\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['label'])\n",
        "print(f\"Test Set Size: {len(test_df)} images\")\n",
        "\n",
        "# --- 2. PREDICTION FUNCTION ---\n",
        "def get_img_array(img_path, size):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "    img = tf.image.resize(img, (size, size))\n",
        "    # Crucial: Use EfficientNet Preprocessing\n",
        "    img = tf.keras.applications.efficientnet.preprocess_input(img)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# --- 3. GENERATE REPORT ---\n",
        "print(\"Generating Predictions (this may take a minute)...\")\n",
        "y_true = test_df['label_idx'].values\n",
        "y_pred = []\n",
        "\n",
        "# Loop through test set (safer than batching for order)\n",
        "for path in test_df['filepath'].values:\n",
        "    img = get_img_array(path, IMG_SIZE)\n",
        "    pred_probs = model.predict(img, verbose=0)\n",
        "    y_pred.append(np.argmax(pred_probs))\n",
        "\n",
        "print(\"\\n--- CLASSIFICATION REPORT ---\")\n",
        "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
        "\n",
        "print(\"\\n--- CONFUSION MATRIX ---\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# --- 4. GRAD-CAM FUNCTION ---\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name=\"top_activation\"):\n",
        "    # Create a model that maps the input image to the activations of the last conv layer\n",
        "    # and the output predictions\n",
        "\n",
        "    # Identify the last convolutional layer in EfficientNet\n",
        "    # Usually 'top_activation' or similar. We search for it.\n",
        "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [last_conv_layer.output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# --- 5. VISUALIZE GRAD-CAM ---\n",
        "print(\"\\n--- VISUALIZING MODEL FOCUS (GRAD-CAM) ---\")\n",
        "# Find the last conv layer name automatically\n",
        "for layer in reversed(model.layers):\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization): # EffNet usually ends with BN\n",
        "        continue\n",
        "    if hasattr(layer, 'output_shape') and len(layer.output_shape) == 4:\n",
        "        last_conv_layer_name = layer.name\n",
        "        print(f\"Found Last Conv Layer: {last_conv_layer_name}\")\n",
        "        break\n",
        "\n",
        "# Pick one random image from each class to visualize\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i, class_name in enumerate(CLASS_NAMES):\n",
        "    # Get a random image of this class\n",
        "    sample_row = test_df[test_df['label'] == class_name].sample(1).iloc[0]\n",
        "    img_path = sample_row['filepath']\n",
        "\n",
        "    # Prepare Image\n",
        "    img_array = get_img_array(img_path, IMG_SIZE)\n",
        "\n",
        "    # Generate Heatmap\n",
        "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "    # Display\n",
        "    ax = plt.subplot(2, 3, i + 1)\n",
        "\n",
        "    # Load original image for overlay\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    # Use jet colormap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((IMG_SIZE, IMG_SIZE))\n",
        "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * 0.4 + img\n",
        "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.title(f\"True: {class_name}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Kga6LqJ7XaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aded610-04b9-494e-875d-d5c171a0a8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from /content/drive/MyDrive/Pneumonia_Advanced_Project/efficientnet_b0_optimized_v7.keras...\n",
            "Preparing Test Set...\n",
            "Test Set Size: 3004 images\n",
            "Generating Predictions (this may take a minute)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aiyfipw069qi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}