{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhOE8YLHWYon",
        "outputId": "cddb3888-0bb6-46ef-e63a-ff523cbbf170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Setup Shuru ---\n",
            "Target Folder: /content/local_images\n",
            "Copying Copy of images_archive.tar.gz...\n",
            "Copy complete in 51.17 seconds.\n",
            "Extracting and ADDING images to /content/local_images...\n",
            "Extraction complete in 24.03 seconds.\n",
            "\n",
            "âœ… --- READY TO TRAIN! Images are in /content/local_images ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# --- 1. Sirf is line ko change karein ---\n",
        "# ğŸ”´ Pehli baar 'images1_archive.tar.gz' likhein\n",
        "#    Doosri baar 'images2_archive.tar.gz' likhein, etc.\n",
        "ARCHIVE_FILE_NAME = \"Copy of images_archive.tar.gz\"\n",
        "\n",
        "# --- 2. In paths ko hamesha same rehne dein ---\n",
        "DRIVE_BASE_PATH = \"/content/drive/MyDrive/images\"\n",
        "# Yeh hamesha same folder rahega taake images jama (collect) ho sakein\n",
        "LOCAL_IMAGE_DIR = \"/content/local_images\"\n",
        "\n",
        "# --- 3. Baqi code ab automatically kaam karega ---\n",
        "DRIVE_TAR_PATH = os.path.join(DRIVE_BASE_PATH, ARCHIVE_FILE_NAME)\n",
        "LOCAL_TAR_PATH = f\"/content/{ARCHIVE_FILE_NAME}\"\n",
        "\n",
        "# Yeh line check karti hai ke folder hai ya nahi. Agar hai, to usay istemaal karti hai.\n",
        "os.makedirs(LOCAL_IMAGE_DIR, exist_ok=True)\n",
        "print(f\"--- Setup Shuru ---\")\n",
        "print(f\"Target Folder: {LOCAL_IMAGE_DIR}\")\n",
        "\n",
        "# --- FAST COPY ---\n",
        "print(f\"Copying {ARCHIVE_FILE_NAME}...\")\n",
        "start_time = time.time()\n",
        "!cp \"{DRIVE_TAR_PATH}\" \"{LOCAL_TAR_PATH}\"\n",
        "print(f\"Copy complete in {(time.time() - start_time):.2f} seconds.\")\n",
        "\n",
        "# --- FAST UNPACK (ADD) ---\n",
        "print(f\"Extracting and ADDING images to {LOCAL_IMAGE_DIR}...\")\n",
        "start_time = time.time()\n",
        "# Yeh command purani files ko delete nahi karta, sirf nayi files add karta hai\n",
        "!tar -xzf \"{LOCAL_TAR_PATH}\" -C \"{LOCAL_IMAGE_DIR}\"\n",
        "print(f\"Extraction complete in {(time.time() - start_time):.2f} seconds.\")\n",
        "\n",
        "print(f\"\\nâœ… --- READY TO TRAIN! Images are in {LOCAL_IMAGE_DIR} ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# The path where you extracted the images\n",
        "LOCAL_IMAGE_DIR = \"/content/local_images\"\n",
        "\n",
        "try:\n",
        "    file_count = len(os.listdir(LOCAL_IMAGE_DIR))\n",
        "    print(f\"âœ… Success! Found {file_count} images in '{LOCAL_IMAGE_DIR}'.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"âŒ Error: Could not find the directory '{LOCAL_IMAGE_DIR}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr4TUTTVWm8B",
        "outputId": "ff393ce9-b5a7-4b05-b8b2-3fcef4d0f488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Success! Found 30051 images in '/content/local_images'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# --- 1. Configuration (Set Your Parameters) ---\n",
        "BATCH_SIZE = 32\n",
        "IMG_WIDTH, IMG_HEIGHT = 300, 300\n",
        "\n",
        "EPOCHS_FINE_TUNE = 20\n",
        "# Hum purana (original) low learning rate istemaal karein ge\n",
        "LEARNING_RATE_FINE_TUNE = 1e-4\n",
        "\n",
        "# --- 2. Paths (Apne hisaab se set karein) ---\n",
        "SAVED_WEIGHTS_PATH = '/content/drive/MyDrive/images/v2_finetuned_best.keras'\n",
        "FINAL_MODEL_PATH = '/content/drive/MyDrive/images/v2_finetuned_best1.keras'\n",
        "IMAGE_DIR = '/content/local_images'\n",
        "CLEAN_CSV_PATH = '/content/drive/MyDrive/images/master_tf_clean.csv'\n",
        "\n",
        "# --- 3. Class Weights and Names ---\n",
        "CLASS_WEIGHTS_DICT = {\n",
        "    0: 1.38, 1: 0.83, 2: 0.33, 3: 2.23, 4: 1.96, 5: 7.15\n",
        "}\n",
        "CLASS_NAMES = ['COVID-19', 'Lung Opacity', 'Normal', 'Pneumonia (Bacterial)', 'Pneumonia (Viral)', 'Tuberculosis']\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "# --- 4. Function Definitions (Simplified) ---\n",
        "\n",
        "def load_and_preprocess(filepath, label):\n",
        "    img = tf.io.read_file(filepath)\n",
        "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "    img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "    img = tf.keras.applications.densenet.preprocess_input(img)\n",
        "    return img, label\n",
        "\n",
        "def build_dataset(df, augment=False):\n",
        "    augmentation_layers = tf.keras.Sequential([\n",
        "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "        tf.keras.layers.RandomRotation(0.1),\n",
        "        tf.keras.layers.RandomZoom(0.1),\n",
        "    ])\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((df['filepath'].values, df['label_idx'].values))\n",
        "    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if augment:\n",
        "        dataset = dataset.map(lambda x, y: (augmentation_layers(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def build_densenet_model():\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "# --- 5. Data Loading & Pipeline Execution ---\n",
        "print(f\"Loading data from {CLEAN_CSV_PATH}...\")\n",
        "df = pd.read_csv(CLEAN_CSV_PATH)\n",
        "df['filepath'] = df['filename'].apply(lambda x: os.path.join(IMAGE_DIR, x))\n",
        "class_indices = {name: i for i, name in enumerate(CLASS_NAMES)}\n",
        "df['label_idx'] = df['label'].map(class_indices)\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['label'])\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=(len(test_df)/len(train_val_df)), random_state=42, stratify=train_val_df['label'])\n",
        "train_dataset = build_dataset(train_df, augment=True)\n",
        "val_dataset = build_dataset(val_df)\n",
        "test_dataset = build_dataset(test_df)\n",
        "\n",
        "# --- 6. Model Build and Weight Load (Skip Stage 1) ---\n",
        "print(\"Building DenseNet-121 model structure...\")\n",
        "model = build_densenet_model()\n",
        "\n",
        "print(f\"--- STAGE 1 SKIPPED ---\")\n",
        "print(f\"Loading best weights (83.42% Peak) from '{SAVED_WEIGHTS_PATH}'...\")\n",
        "try:\n",
        "    model.load_weights(SAVED_WEIGHTS_PATH)\n",
        "    print(\"âœ… Weights loaded successfully. Starting Fine-Tuning from 83.42%.\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ERROR: Weights load nahi huin. {e}\")\n",
        "    raise\n",
        "\n",
        "# --- 7. STAGE 2: Simple Fine-Tuning Execution (PURANA CODE) ---\n",
        "print(\"\\n--- STAGE 2: Simple Fine-tuning the FULL model ---\")\n",
        "\n",
        "# (A) Index 4 par Base model ko pakrein\n",
        "base_model = model.layers[4]\n",
        "\n",
        "# (B) Poora Base Model unfreeze karein\n",
        "base_model.trainable = True\n",
        "\n",
        "print(\"âœ… Poora Base Model (Index 4) Fine-tuning ke liye unfreeze kar diya gaya hai.\")\n",
        "\n",
        "# (C) Model ko compile karein\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_FINE_TUNE),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# (D) Callbacks (Puranay callbacks)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint(FINAL_MODEL_PATH, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# NAYA CALLBACK: Agar 3 epochs tak behtari na ho to LR kam karo\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1)\n",
        "\n",
        "# (E) Training run karein\n",
        "history_fine_tune = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS_FINE_TUNE,\n",
        "    validation_data=val_dataset,\n",
        "    # Yahan list ko update karein\n",
        "    callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
        "    class_weight=CLASS_WEIGHTS_DICT\n",
        ")\n",
        "print(\"--- Simple Fine-Tuning Complete! ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvuFewxuWpzN",
        "outputId": "1b8d524c-345c-4d67-88c5-3a15e4640d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/drive/MyDrive/images/master_tf_clean.csv...\n",
            "Building DenseNet-121 model structure...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "--- STAGE 1 SKIPPED ---\n",
            "Loading best weights (83.42% Peak) from '/content/drive/MyDrive/images/v2_finetuned_best.keras'...\n",
            "âœ… Weights loaded successfully. Starting Fine-Tuning from 83.42%.\n",
            "\n",
            "--- STAGE 2: Simple Fine-tuning the FULL model ---\n",
            "âœ… Poora Base Model (Index 4) Fine-tuning ke liye unfreeze kar diya gaya hai.\n",
            "Epoch 1/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774ms/step - accuracy: 0.7893 - loss: 0.4793\n",
            "Epoch 1: val_loss improved from inf to 0.51810, saving model to /content/drive/MyDrive/images/v2_finetuned_best1.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 829ms/step - accuracy: 0.7893 - loss: 0.4793 - val_accuracy: 0.8152 - val_loss: 0.5181 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.8024 - loss: 0.4586\n",
            "Epoch 2: val_loss improved from 0.51810 to 0.48591, saving model to /content/drive/MyDrive/images/v2_finetuned_best1.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 786ms/step - accuracy: 0.8024 - loss: 0.4586 - val_accuracy: 0.8242 - val_loss: 0.4859 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - accuracy: 0.8110 - loss: 0.4453\n",
            "Epoch 3: val_loss did not improve from 0.48591\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 773ms/step - accuracy: 0.8110 - loss: 0.4453 - val_accuracy: 0.8262 - val_loss: 0.4867 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742ms/step - accuracy: 0.8083 - loss: 0.4431\n",
            "Epoch 4: val_loss improved from 0.48591 to 0.46817, saving model to /content/drive/MyDrive/images/v2_finetuned_best1.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 768ms/step - accuracy: 0.8083 - loss: 0.4431 - val_accuracy: 0.8296 - val_loss: 0.4682 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738ms/step - accuracy: 0.8112 - loss: 0.4418\n",
            "Epoch 5: val_loss did not improve from 0.46817\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m575s\u001b[0m 766ms/step - accuracy: 0.8112 - loss: 0.4418 - val_accuracy: 0.8286 - val_loss: 0.4812 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737ms/step - accuracy: 0.8172 - loss: 0.4330\n",
            "Epoch 6: val_loss did not improve from 0.46817\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 759ms/step - accuracy: 0.8172 - loss: 0.4330 - val_accuracy: 0.8282 - val_loss: 0.4828 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.8110 - loss: 0.4355\n",
            "Epoch 7: val_loss improved from 0.46817 to 0.44932, saving model to /content/drive/MyDrive/images/v2_finetuned_best1.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m643s\u001b[0m 787ms/step - accuracy: 0.8110 - loss: 0.4355 - val_accuracy: 0.8395 - val_loss: 0.4493 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - accuracy: 0.8152 - loss: 0.4340\n",
            "Epoch 8: val_loss did not improve from 0.44932\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m641s\u001b[0m 814ms/step - accuracy: 0.8152 - loss: 0.4340 - val_accuracy: 0.8336 - val_loss: 0.4592 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - accuracy: 0.8195 - loss: 0.4296\n",
            "Epoch 9: val_loss improved from 0.44932 to 0.44616, saving model to /content/drive/MyDrive/images/v2_finetuned_best1.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m584s\u001b[0m 778ms/step - accuracy: 0.8195 - loss: 0.4296 - val_accuracy: 0.8405 - val_loss: 0.4462 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - accuracy: 0.8200 - loss: 0.4216\n",
            "Epoch 10: val_loss did not improve from 0.44616\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 776ms/step - accuracy: 0.8200 - loss: 0.4216 - val_accuracy: 0.8292 - val_loss: 0.4743 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756ms/step - accuracy: 0.8238 - loss: 0.4065\n",
            "Epoch 11: val_loss did not improve from 0.44616\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m590s\u001b[0m 786ms/step - accuracy: 0.8238 - loss: 0.4065 - val_accuracy: 0.8219 - val_loss: 0.4779 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step - accuracy: 0.8195 - loss: 0.4090\n",
            "Epoch 12: val_loss did not improve from 0.44616\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 795ms/step - accuracy: 0.8195 - loss: 0.4090 - val_accuracy: 0.8282 - val_loss: 0.4755 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.8230 - loss: 0.4086\n",
            "Epoch 13: val_loss improved from 0.44616 to 0.43818, saving model to /content/drive/MyDrive/images/v2_finetuned_best1.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 797ms/step - accuracy: 0.8230 - loss: 0.4086 - val_accuracy: 0.8415 - val_loss: 0.4382 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766ms/step - accuracy: 0.8225 - loss: 0.4106\n",
            "Epoch 14: val_loss did not improve from 0.43818\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 793ms/step - accuracy: 0.8225 - loss: 0.4106 - val_accuracy: 0.8053 - val_loss: 0.5203 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - accuracy: 0.8283 - loss: 0.4030\n",
            "Epoch 15: val_loss did not improve from 0.43818\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 778ms/step - accuracy: 0.8283 - loss: 0.4030 - val_accuracy: 0.8366 - val_loss: 0.4414 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.8270 - loss: 0.4006\n",
            "Epoch 16: val_loss did not improve from 0.43818\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 785ms/step - accuracy: 0.8270 - loss: 0.4006 - val_accuracy: 0.8356 - val_loss: 0.4468 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759ms/step - accuracy: 0.8267 - loss: 0.3934\n",
            "Epoch 17: val_loss improved from 0.43818 to 0.43504, saving model to /content/drive/MyDrive/images/v2_finetuned_best1.keras\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 784ms/step - accuracy: 0.8267 - loss: 0.3934 - val_accuracy: 0.8402 - val_loss: 0.4350 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772ms/step - accuracy: 0.8310 - loss: 0.3944\n",
            "Epoch 18: val_loss did not improve from 0.43504\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 799ms/step - accuracy: 0.8310 - loss: 0.3944 - val_accuracy: 0.8212 - val_loss: 0.4769 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758ms/step - accuracy: 0.8335 - loss: 0.3896\n",
            "Epoch 19: val_loss did not improve from 0.43504\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 784ms/step - accuracy: 0.8335 - loss: 0.3896 - val_accuracy: 0.8372 - val_loss: 0.4405 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - accuracy: 0.8371 - loss: 0.3874\n",
            "Epoch 20: val_loss did not improve from 0.43504\n",
            "\u001b[1m751/751\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 780ms/step - accuracy: 0.8371 - loss: 0.3874 - val_accuracy: 0.8256 - val_loss: 0.4574 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 17.\n",
            "--- Simple Fine-Tuning Complete! ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Evaluating model on the hold-out test set...\")\n",
        "# Load the best model saved by ModelCheckpoint\n",
        "model.load_weights(\"/content/drive/MyDrive/images/v2_finetuned_best1.keras\")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# --- IMPORTANT: Generate Classification Report ---\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Generating classification report and confusion matrix...\")\n",
        "# Get all true labels and predictions from the test set\n",
        "y_true = []\n",
        "y_pred_probs = []\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred_probs.extend(model.predict(images))\n",
        "\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSV0OYOFZlxt",
        "outputId": "f4c58010-367b-4867-b84a-1dc93bd24b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on the hold-out test set...\n",
            "\u001b[1m94/94\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.8242 - loss: 0.4648\n",
            "Test Loss: 0.4554998576641083\n",
            "Test Accuracy: 0.826564610004425\n",
            "Generating classification report and confusion matrix...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n",
            "\n",
            "--- Confusion Matrix ---\n",
            "[[ 302   16   31    2    0   11]\n",
            " [  29  452  105    0    0   15]\n",
            " [  34   46 1334   45    6   27]\n",
            " [   0    0    0  218    6    0]\n",
            " [   0    0    4  143  108    0]\n",
            " [   1    0    0    0    0   69]]\n",
            "\n",
            "--- Classification Report ---\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "             COVID-19       0.83      0.83      0.83       362\n",
            "         Lung Opacity       0.88      0.75      0.81       601\n",
            "               Normal       0.91      0.89      0.90      1492\n",
            "Pneumonia (Bacterial)       0.53      0.97      0.69       224\n",
            "    Pneumonia (Viral)       0.90      0.42      0.58       255\n",
            "         Tuberculosis       0.57      0.99      0.72        70\n",
            "\n",
            "             accuracy                           0.83      3004\n",
            "            macro avg       0.77      0.81      0.75      3004\n",
            "         weighted avg       0.85      0.83      0.83      3004\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cb4R-JTfIXqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}